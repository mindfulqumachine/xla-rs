<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>xla-rs: Building an LLM Framework in Rust</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-3ffea832.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-83977558.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">xla-rs: Building an LLM Framework in Rust</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/mindfulqumachine/xla-rs" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="chapter-1-introduction--philosophy"><a class="header" href="#chapter-1-introduction--philosophy">Chapter 1: Introduction &amp; Philosophy</a></h1>
<blockquote>
<p>“What I cannot create, I do not understand.” — Richard Feynman</p>
</blockquote>
<p>Welcome to <strong>xla-rs</strong>. This book is a journey through the internals of Large Language Models (LLMs). We aren’t just going to use them; we are going to build one, from scratch, in Rust.</p>
<h2 id="philosophy"><a class="header" href="#philosophy">Philosophy</a></h2>
<p>Our approach is guided by three principles:</p>
<ol>
<li><strong>Pure Rust</strong>: We avoid binding to C++ libraries like Torch or TensorFlow. We want to understand the entire stack, down to the memory layout of a tensor.</li>
<li><strong>Pedantic Implementation</strong>: We prioritize clarity over raw performance (initially). We want the code to map 1:1 with the mathematical equations.</li>
<li><strong>From Scratch</strong>: We start with <code>Vec&lt;f32&gt;</code> and end with a distributed inference server.</li>
</ol>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>You will need:</p>
<ul>
<li><strong>Rust</strong>: Latest stable version (<code>rustup update stable</code>).</li>
<li><strong>A Curiosity for Math</strong>: We will cover the necessary linear algebra and calculus as we go.</li>
</ul>
<h2 id="setting-up"><a class="header" href="#setting-up">Setting Up</a></h2>
<p>Clone the repository and run the setup test to ensure everything is working.</p>
<pre><code class="language-bash">git clone https://github.com/mindfulqumachine/xla-rs.git
cd xla-rs
cargo test --test chapter_01_setup
</code></pre>
<p>If the test passes, you are ready to begin!</p>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-2-tensors-the-bedrock"><a class="header" href="#chapter-2-tensors-the-bedrock">Chapter 2: Tensors (The Bedrock)</a></h1>
<p>At the heart of every deep learning framework lies the <strong>Tensor</strong>. A tensor is simply a generalization of vectors and matrices to $N$ dimensions.</p>
<p>In <code>xla-rs</code>, our <code>Tensor</code> struct is defined as:</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Tensor&lt;T, const RANK: usize, D: Device = Cpu&gt; {
    shape: [usize; RANK],
    strides: [usize; RANK],
    data: D::Storage&lt;T&gt;,
    device: D,
}
<span class="boring">}</span></code></pre>
<h2 id="memory-layout"><a class="header" href="#memory-layout">Memory Layout</a></h2>
<p>We store data in a single, contiguous <code>Vec&lt;T&gt;</code>. This is crucial for performance (cache locality) and interoperability with hardware accelerators.</p>
<h3 id="shapes-and-strides"><a class="header" href="#shapes-and-strides">Shapes and Strides</a></h3>
<p>How do we map an N-dimensional index $(i, j, k)$ to a flat index in the vector? We use <strong>strides</strong>.</p>
<p>The stride for a dimension tells us how many elements we need to skip in memory to move one step along that dimension.</p>
<p>For a tensor of shape <code>[2, 3]</code>:</p>
<ul>
<li><code>strides[1]</code> (columns) is 1.</li>
<li><code>strides[0]</code> (rows) is 3 (the size of the next dimension).</li>
</ul>
<p>The flat index is calculated as:
$$ \text{index} = \sum_{d=0}^{RANK-1} i_d \times \text{strides}[d] $$</p>
<h2 id="operations"><a class="header" href="#operations">Operations</a></h2>
<p>We implement basic arithmetic operations (<code>Add</code>, <code>Mul</code>) and Matrix Multiplication.</p>
<h3 id="broadcasting"><a class="header" href="#broadcasting">Broadcasting</a></h3>
<p>Broadcasting allows us to perform operations on tensors of different shapes.</p>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>Full broadcasting support (like NumPy) is currently a work in progress. For now, shapes must match exactly.</p>
</blockquote>
<h2 id="hands-on"><a class="header" href="#hands-on">Hands On</a></h2>
<p>Let’s create some tensors!</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use xla_rs::tensor::Tensor;

let data = vec![1.0, 2.0, 3.0, 4.0];
let t = Tensor::&lt;f32, 2&gt;::new(data, [2, 2]).unwrap();
println!("{:?}", t);
<span class="boring">}</span></code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-3-automatic-differentiation"><a class="header" href="#chapter-3-automatic-differentiation">Chapter 3: Automatic Differentiation</a></h1>
<p>Training neural networks requires calculating gradients. We use <strong>Automatic Differentiation (Autograd)</strong> to do this efficiently.</p>
<h2 id="the-tape"><a class="header" href="#the-tape">The Tape</a></h2>
<p>We implement a <strong>Define-by-Run</strong> (or Tape-based) autograd system, similar to PyTorch.</p>
<ol>
<li><strong>Variable</strong>: A wrapper around a <code>Tensor</code> that tracks its gradient and the operation that created it.</li>
<li><strong>GraphNode</strong>: A trait representing an operation in the computation graph.</li>
<li><strong>Backward Pass</strong>: We traverse the graph in reverse topological order to compute gradients.</li>
</ol>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Variable&lt;T, const RANK: usize&gt; {
    pub data: Tensor&lt;T, RANK, Cpu&gt;,
    pub grad: Rc&lt;RefCell&lt;Option&lt;Tensor&lt;T, RANK, Cpu&gt;&gt;&gt;&gt;,
    pub node: Option&lt;Rc&lt;dyn GraphNode&gt;&gt;,
}
<span class="boring">}</span></code></pre>
<h2 id="the-backward-pass"><a class="header" href="#the-backward-pass">The Backward Pass</a></h2>
<p>When you call <code>.backward()</code> on a scalar variable (the loss), we:</p>
<ol>
<li>Seed the gradient of the loss with 1.0.</li>
<li>Topologically sort the graph (to ensure dependencies are processed first).</li>
<li>Call <code>.backward()</code> on each node, propagating gradients to parents.</li>
</ol>
<h2 id="example"><a class="header" href="#example">Example</a></h2>
<pre><code class="language-rust ignore">use xla_rs::tensor::Tensor;
use xla_rs::autograd::Variable;

let a = Variable::new(Tensor::from(2.0));
let b = Variable::new(Tensor::from(3.0));

// c = a * b
let c = a.clone() * b.clone(); 

c.backward();

// da = dc/da * grad_c = b * 1 = 3
// db = dc/db * grad_c = a * 1 = 2</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-4-neural-network-primitives"><a class="header" href="#chapter-4-neural-network-primitives">Chapter 4: Neural Network Primitives</a></h1>
<p>With tensors and autograd in place, we can build neural network layers.</p>
<h2 id="the-module-trait"><a class="header" href="#the-module-trait">The Module Trait</a></h2>
<p>We define a <code>Module</code> trait that all layers must implement. Currently, it’s a marker trait for <code>Debug + Send + Sync</code>.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Module&lt;T: TensorElem&gt;: Debug + Send + Sync {}
<span class="boring">}</span></code></pre>
<h2 id="the-linear-layer"><a class="header" href="#the-linear-layer">The Linear Layer</a></h2>
<p>The <code>Linear</code> layer performs an affine transformation: $y = xA^T + b$.</p>
<p>It holds:</p>
<ul>
<li><code>weight</code>: Shape <code>[out_features, in_features]</code></li>
<li><code>bias</code>: Optional, Shape <code>[out_features]</code></li>
</ul>
<p>We implement <code>forward</code> to handle both 2D (matrix) and 3D (batched) inputs.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct Linear&lt;T: TensorElem&gt; {
    pub weight: Tensor&lt;T, 2, Cpu&gt;,
    pub bias: Option&lt;Tensor&lt;T, 1, Cpu&gt;&gt;,
}
<span class="boring">}</span></code></pre>
<h2 id="example-1"><a class="header" href="#example-1">Example</a></h2>
<pre><code class="language-rust ignore">use xla_rs::tensor::Tensor;
use xla_rs::nn::Linear;

let weight = Tensor::&lt;f32, 2&gt;::ones([2, 2]);
let linear = Linear::new(weight, None);
let input = Tensor::&lt;f32, 2&gt;::ones([1, 2]);

let output = linear.forward(&amp;input).unwrap();</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-5-the-mechanics-of-attention"><a class="header" href="#chapter-5-the-mechanics-of-attention">Chapter 5: The Mechanics of Attention</a></h1>
<p>Attention is the mechanism that allows the model to “focus” on different parts of the input sequence.</p>
<h2 id="scaled-dot-product-attention"><a class="header" href="#scaled-dot-product-attention">Scaled Dot-Product Attention</a></h2>
<p>The core operation is:</p>
<p>$$ \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V $$</p>
<p>Where:</p>
<ul>
<li>$Q$ (Query): What I’m looking for.</li>
<li>$K$ (Key): What I have.</li>
<li>$V$ (Value): What I pass on.</li>
</ul>
<h2 id="rotary-positional-embeddings-rope"><a class="header" href="#rotary-positional-embeddings-rope">Rotary Positional Embeddings (RoPE)</a></h2>
<p>Transformers process tokens in parallel, so they have no inherent notion of order. RoPE injects position information by rotating the Query and Key vectors in the complex plane.</p>
<p>$$ f_{q,k}(x_m, m) = x_m e^{im\theta} $$</p>
<p>In <code>xla-rs</code>, we implement this in <code>apply_rope</code>.</p>
<h2 id="grouped-query-attention-gqa"><a class="header" href="#grouped-query-attention-gqa">Grouped Query Attention (GQA)</a></h2>
<p>Gemma uses GQA, an optimization where multiple query heads share a single key/value head. This reduces memory bandwidth (KV cache size) while maintaining performance.</p>
<h2 id="implementation"><a class="header" href="#implementation">Implementation</a></h2>
<p>Our <code>MultiHeadAttention</code> struct handles:</p>
<ol>
<li>Projecting inputs to $Q, K, V$.</li>
<li>Applying RoPE.</li>
<li>Repeating KV heads (for GQA).</li>
<li>Computing attention scores and output.</li>
</ol>
<pre><code class="language-rust ignore">pub struct MultiHeadAttention&lt;T: TensorElem&gt; {
    pub q_proj: Linear&lt;T&gt;,
    pub k_proj: Linear&lt;T&gt;,
    pub v_proj: Linear&lt;T&gt;,
    pub o_proj: Linear&lt;T&gt;,
    // ...
}</code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-6-the-gemma-architecture"><a class="header" href="#chapter-6-the-gemma-architecture">Chapter 6: The Gemma Architecture</a></h1>
<p>Gemma is a family of lightweight, state-of-the-art open models from Google. In this chapter, we assemble the components from previous chapters into the full Gemma architecture.</p>
<h2 id="the-gemma-block"><a class="header" href="#the-gemma-block">The Gemma Block</a></h2>
<p>Each block consists of:</p>
<ol>
<li><strong>Input RMSNorm</strong></li>
<li><strong>Multi-Head Attention</strong> (with RoPE)</li>
<li><strong>Post-Attention RMSNorm</strong></li>
<li><strong>MLP</strong> (Feed-Forward Network)</li>
</ol>
<p>$$ x = x + \text{Attention}(\text{RMSNorm}(x)) $$
$$ x = x + \text{MLP}(\text{RMSNorm}(x)) $$</p>
<p>Note that Gemma uses <strong>Pre-Norm</strong> with a twist: the residual connection is added <em>after</em> the block.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct GemmaBlock&lt;T: TensorElem&gt; {
    pub self_attn: MultiHeadAttention&lt;T&gt;,
    pub mlp: MLP&lt;T&gt;,
    pub input_layernorm: RMSNorm&lt;T&gt;,
    pub post_attention_layernorm: RMSNorm&lt;T&gt;,
}
<span class="boring">}</span></code></pre>
<h2 id="the-mlp"><a class="header" href="#the-mlp">The MLP</a></h2>
<p>Gemma uses a Gated Linear Unit (GLU) variant.</p>
<p>$$ \text{MLP}(x) = \text{Down}(\text{SiLU}(\text{Gate}(x)) \odot \text{Up}(x)) $$</p>
<h2 id="the-full-model"><a class="header" href="#the-full-model">The Full Model</a></h2>
<p>The <code>GemmaModel</code> is simply a stack of <code>GemmaBlock</code>s followed by a final normalization.</p>
<pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct GemmaModel&lt;T: TensorElem&gt; {
    pub layers: Vec&lt;GemmaBlock&lt;T&gt;&gt;,
    pub norm: RMSNorm&lt;T&gt;,
}
<span class="boring">}</span></code></pre>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-7-inference-optimizations"><a class="header" href="#chapter-7-inference-optimizations">Chapter 7: Inference Optimizations</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover"><a class="header" href="#topics-to-cover">Topics to Cover</a></h2>
<ul>
<li><strong>KV Caching</strong>: Avoiding re-computation of past keys and values.</li>
<li><strong>PagedAttention</strong>: Managing KV cache memory efficiently (like vLLM).</li>
<li><strong>Decoding Strategies</strong>: Greedy, Top-K, Top-P.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-8-distributed-inference"><a class="header" href="#chapter-8-distributed-inference">Chapter 8: Distributed Inference</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-1"><a class="header" href="#topics-to-cover-1">Topics to Cover</a></h2>
<ul>
<li><strong>Tensor Parallelism (TP)</strong>: Splitting tensors across devices.</li>
<li><strong>Pipeline Parallelism (PP)</strong>: Splitting layers across devices.</li>
<li><strong>Sharding Strategies</strong>: How to shard weights and activations.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-9-the-training-loop"><a class="header" href="#chapter-9-the-training-loop">Chapter 9: The Training Loop</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-2"><a class="header" href="#topics-to-cover-2">Topics to Cover</a></h2>
<ul>
<li><strong>Optimizers</strong>: AdamW, SGD.</li>
<li><strong>Loss Functions</strong>: Cross-Entropy.</li>
<li><strong>Data Loading</strong>: Efficient batching and pre-fetching.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-10-serving"><a class="header" href="#chapter-10-serving">Chapter 10: Serving</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-3"><a class="header" href="#topics-to-cover-3">Topics to Cover</a></h2>
<ul>
<li><strong>Continuous Batching</strong>: Processing requests as they arrive.</li>
<li><strong>API Server</strong>: Building an OpenAI-compatible API.</li>
<li><strong>Metrics &amp; Monitoring</strong>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-11-state-space-models"><a class="header" href="#chapter-11-state-space-models">Chapter 11: State Space Models</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-4"><a class="header" href="#topics-to-cover-4">Topics to Cover</a></h2>
<ul>
<li><strong>Mamba</strong>: Linear-time sequence modeling.</li>
<li><strong>S4</strong>: Structured State Spaces.</li>
<li><strong>Hybrids</strong>: Combining Attention and SSMs.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-12-generative-art-diffusion"><a class="header" href="#chapter-12-generative-art-diffusion">Chapter 12: Generative Art: Diffusion</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-5"><a class="header" href="#topics-to-cover-5">Topics to Cover</a></h2>
<ul>
<li><strong>UNets</strong>: The backbone of diffusion.</li>
<li><strong>Denoising</strong>: The reverse diffusion process.</li>
<li><strong>Schedulers</strong>: DDPM, DDIM, Euler.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-13-communication-collectives"><a class="header" href="#chapter-13-communication-collectives">Chapter 13: Communication Collectives</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-6"><a class="header" href="#topics-to-cover-6">Topics to Cover</a></h2>
<ul>
<li><strong>NCCL Alternative</strong>: Building pure Rust collectives.</li>
<li><strong>Ring AllReduce</strong>: The classic algorithm.</li>
<li><strong>Tree AllReduce</strong>: Optimizing for latency.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-14-reinforcement-learning"><a class="header" href="#chapter-14-reinforcement-learning">Chapter 14: Reinforcement Learning</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-7"><a class="header" href="#topics-to-cover-7">Topics to Cover</a></h2>
<ul>
<li><strong>RLHF</strong>: Reinforcement Learning from Human Feedback.</li>
<li><strong>PPO</strong>: Proximal Policy Optimization.</li>
<li><strong>DPO</strong>: Direct Preference Optimization.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div>
<h1 id="chapter-15-quantization"><a class="header" href="#chapter-15-quantization">Chapter 15: Quantization</a></h1>
<blockquote class="blockquote-tag blockquote-tag-note">
<p class="blockquote-tag-title"><svg viewbox="0 0 16 16" width="18" height="18"><path d="M0 8a8 8 0 1 1 16 0A8 8 0 0 1 0 8Zm8-6.5a6.5 6.5 0 1 0 0 13 6.5 6.5 0 0 0 0-13ZM6.5 7.75A.75.75 0 0 1 7.25 7h1a.75.75 0 0 1 .75.75v2.75h.25a.75.75 0 0 1 0 1.5h-2a.75.75 0 0 1 0-1.5h.25v-2h-.25a.75.75 0 0 1-.75-.75ZM8 6a1 1 0 1 1 0-2 1 1 0 0 1 0 2Z"></path></svg>Note</p>
<p>This chapter is under construction.</p>
</blockquote>
<h2 id="topics-to-cover-8"><a class="header" href="#topics-to-cover-8">Topics to Cover</a></h2>
<ul>
<li><strong>int8 / fp8</strong>: Low-precision arithmetic.</li>
<li><strong>Calibration</strong>: Determining scale factors.</li>
<li><strong>AWQ / GPTQ</strong>: Advanced quantization techniques.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>


        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
