# Chapter 8: Distributed Inference

> \[!NOTE]
> This chapter is under construction.

## Topics to Cover
- **Tensor Parallelism (TP)**: Splitting tensors across devices.
- **Pipeline Parallelism (PP)**: Splitting layers across devices.
- **Sharding Strategies**: How to shard weights and activations.
