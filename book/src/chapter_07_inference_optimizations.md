# Chapter 7: Inference Optimizations

> [!NOTE]
> This chapter is under construction.

## Topics to Cover
- **KV Caching**: Avoiding re-computation of past keys and values.
- **PagedAttention**: Managing KV cache memory efficiently (like vLLM).
- **Decoding Strategies**: Greedy, Top-K, Top-P.
