[package]
name = "xla_rs"
version = "0.1.0-alpha.1"
edition = "2024"
description = "A pure Rust implementation of LLM building blocks and tensors."
license = "MIT"
repository = "https://github.com/mindfulqumachine/xla-rs"
documentation = "https://mindfulqumachine.github.io/xla-rs/book/"

[features]
default = []
# Feature to include pre-built model architectures (e.g. Gemma).
# Gated to reduce compilation time for users who only need core tensor operations.
models = []
# Feature to enable XLA backend for distributed training.
xla-backend = ["dep:xla"]

[dependencies]
anyhow = "1.0.100"
num-traits = "0.2.19"
rand = "0.9.2"
rayon = "1.11.0"
thiserror = "2.0.17"
xla-rs-kernels = { path = "../kernels" }
const_soft_float = "0.1.4"
safetensors = "0.7.0"
memmap2 = "0.9.9"
tokenizers = "0.22.1"
xla = { version = "0.1.6", optional = true }
crossbeam = "0.8.4"

[dev-dependencies]
criterion = "0.8.0"
tempfile = "3.14.0"

[[bench]]
name = "transpose_benchmark"
harness = false

[[bench]]
name = "matmul_benchmark"
harness = false

[[bench]]
name = "attention_benchmark"
harness = false
